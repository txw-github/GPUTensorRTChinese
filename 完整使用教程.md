# RTX 3060 Ti 中文视频转录系统 - 完整使用教程

## 项目结构说明

这个项目包含三种不同的使用方式，我帮你理清楚：

### 1. 主要使用方式：Web应用 (推荐)

**架构：**
```
前端 (React): client/ 目录
后端 (Node.js): server/ 目录  
共享类型: shared/ 目录
```

**启动命令：**
```bash
npm run dev
```

**访问方式：**
- 前端界面: http://localhost:5173 (Vite开发服务器)
- 后端API: http://localhost:5000 (Express服务器)

### 2. 备用方式：Python独立脚本

**文件说明：**
- `app.py` - FastAPI版本后端
- `windows_transcriber.py` - 简化版本，有问题需要修复

### 3. 一键安装：批处理脚本

**文件说明：**
- `windows_installer.bat` - 自动安装脚本
- 各种`.bat`文件 - Windows启动脚本

## 推荐使用流程

### 第一步：环境准备

#### 方式A：一键安装 (适合普通用户)
1. 右键点击 `windows_installer.bat`
2. 选择"以管理员身份运行"
3. 等待自动安装完成
4. 双击桌面快捷方式启动

#### 方式B：手动安装 (适合开发者)
1. 安装 Node.js 20+ 和 Python 3.10+
2. 安装NVIDIA驱动 522.06+ 和 CUDA 12.1+
3. 在项目目录运行：
```bash
npm install
```

### 第二步：启动系统

#### Web应用启动 (主要方式)
```bash
# 在项目根目录运行
npm run dev

# 系统会同时启动：
# - 前端开发服务器 (端口5173)
# - 后端API服务器 (端口5000)
```

#### 验证启动成功
1. 打开浏览器访问: http://localhost:5173
2. 检查页面是否正常显示
3. 右侧系统监控应显示RTX 3060 Ti状态

### 第三步：使用转录功能

#### 1. 检查GPU状态
- 查看右侧"系统监控"面板
- 确认显示"RTX 3060 Ti 8GB 专业级AI加速卡"
- TensorRT状态应为绿色

#### 2. 配置AI模型
- 选择合适模型：
  - **Whisper Large V3**: 最高精度，电视剧推荐
  - **Whisper Medium**: 平衡选择，日常使用
  - **FiredASR中文版**: 专业中文，方言支持
- 开启"TensorRT加速"
- 开启"RTX 3060 Ti专项优化"

#### 3. 上传视频文件
- 拖拽视频到上传区域
- 支持格式：MP4, MKV, AVI, MOV
- 最大文件：10GB
- 支持分辨率：480p-4K

#### 4. 监控转录进度
- 在"转录队列"查看实时进度
- 观察GPU使用率变化
- 查看预计剩余时间

#### 5. 下载转录结果
- 完成后点击"下载字幕"
- 获得包含SRT/VTT/TXT格式的压缩包

## 常见问题解决

### 页面排版问题
如果Web界面显示不正常：

1. **检查端口冲突**
```bash
# 查看端口占用
netstat -ano | findstr :5173
netstat -ano | findstr :5000

# 如有冲突，终止进程
taskkill /PID <进程ID> /F
```

2. **清除缓存重启**
```bash
# 停止服务 (Ctrl+C)
# 清除npm缓存
npm cache clean --force
# 重新启动
npm run dev
```

3. **检查浏览器**
- 使用Chrome或Edge最新版本
- 禁用广告拦截器
- 刷新页面 (Ctrl+F5)

### GPU检测问题

1. **安装NVIDIA驱动**
```bash
# 检查GPU状态
nvidia-smi
```

2. **安装CUDA**
```bash
# 检查CUDA版本
nvcc --version
```

### Python脚本问题

如果使用`windows_transcriber.py`遇到问题：

1. **安装Python依赖**
```bash
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121
pip install openai-whisper librosa soundfile
```

2. **运行脚本**
```bash
python windows_transcriber.py
```

## 性能优化建议

### RTX 3060 Ti最佳配置

**电视剧/电影转录：**
```
模型: Whisper Large V3
TensorRT: 开启
批处理: 4文件
中文优化: 全部开启
预期: 95%+准确率, 实时转录
```

**新闻/访谈：**
```
模型: Whisper Medium  
TensorRT: 开启
批处理: 6文件
中文优化: 智能标点+多音字
预期: 93%+准确率, 1.5倍速度
```

**快速处理：**
```
模型: Whisper Small
TensorRT: 开启
批处理: 8文件
中文优化: 基础设置
预期: 90%+准确率, 2-3倍速度
```

### 系统监控指标

**正常运行状态：**
- GPU使用率: 70-90%
- 显存占用: 4-6GB (75%以下)
- GPU温度: 65-75°C
- 处理速度: 1x-3x实时

**异常情况处理：**
- 显存超过6GB: 降低批处理数量
- 温度超过80°C: 检查散热
- GPU使用率低: 确认TensorRT启用

## 技术支持

### 获取系统信息
运行 `系统信息.bat` 获取诊断信息

### 查看日志
```
logs/system.log - 系统日志
logs/gpu.log - GPU日志  
logs/transcription.log - 转录日志
```

### 重置系统
如果系统出现严重问题：
```bash
# 停止所有服务
# 删除 node_modules
rm -rf node_modules
# 重新安装
npm install
# 重启
npm run dev
```

## 部署到生产环境

### 构建生产版本
```bash
npm run build
npm run start
```

### 服务器部署
参考 `WINDOWS_RTX_3060Ti_部署指南.md` 进行生产环境配置

---

**总结：**
- **推荐使用**: Web应用 (`npm run dev`)
- **备用方案**: Python脚本 (`python windows_transcriber.py`)
- **一键安装**: 批处理脚本 (`windows_installer.bat`)
- **主要优势**: 现代化界面 + RTX 3060 Ti专项优化 + 实时监控