"""
ä¸­æ–‡ç”µè§†å‰§éŸ³é¢‘è½¬æ–‡å­—ç³»ç»Ÿ - ä¸»åº”ç”¨ç¨‹åº
ä¸“ä¸º Windows NVIDIA RTX 3060 Ti ä¼˜åŒ–
æ”¯æŒ Whisperã€FiredASR ç­‰å¤šç§æ¨¡å‹
"""

import os
import sys
import json
import asyncio
import logging
from pathlib import Path
from typing import Optional, List, Dict, Any
import uvicorn
from fastapi import FastAPI, File, UploadFile, Form, HTTPException, Request
from fastapi.staticfiles import StaticFiles
from fastapi.responses import HTMLResponse, FileResponse
from fastapi.middleware.cors import CORSMiddleware
from fastapi.templating import Jinja2Templates

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('logs/app.log', encoding='utf-8'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

# åˆ›å»ºå¿…è¦ç›®å½•
for directory in ['uploads', 'outputs', 'temp', 'logs', 'models']:
    Path(directory).mkdir(exist_ok=True)

# åŠ è½½é…ç½®
try:
    with open('config.json', 'r', encoding='utf-8') as f:
        config = json.load(f)
except FileNotFoundError:
    config = {
        "system": {"gpu_memory_fraction": 0.85, "max_concurrent_jobs": 1},
        "models": {"default": "whisper-large-v3"},
        "chinese_processing": {"variant": "simplified", "multi_pronunciation": True}
    }

# åŠ¨æ€å¯¼å…¥å¤šæ¨¡å‹è½¬å½•å™¨
try:
    from multi_model_transcriber import MultiModelTranscriber, TranscriptionConfig
    TRANSCRIBER_AVAILABLE = True
    logger.info("å¤šæ¨¡å‹è½¬å½•å™¨å·²åŠ è½½")
except ImportError as e:
    TRANSCRIBER_AVAILABLE = False
    logger.warning(f"å¤šæ¨¡å‹è½¬å½•å™¨åŠ è½½å¤±è´¥: {e}")

# åˆ›å»º FastAPI åº”ç”¨
app = FastAPI(
    title="ä¸­æ–‡ç”µè§†å‰§éŸ³é¢‘è½¬æ–‡å­—ç³»ç»Ÿ",
    description="æ”¯æŒå¤šç§AIæ¨¡å‹çš„GPUåŠ é€Ÿä¸­æ–‡è½¬å½•ç³»ç»Ÿ",
    version="1.0.0"
)

# CORS é…ç½®
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# å…¨å±€è½¬å½•å™¨å®ä¾‹
transcriber = None
if TRANSCRIBER_AVAILABLE:
    try:
        transcriber = MultiModelTranscriber()
        logger.info("è½¬å½•å™¨åˆå§‹åŒ–æˆåŠŸ")
    except Exception as e:
        logger.error(f"è½¬å½•å™¨åˆå§‹åŒ–å¤±è´¥: {e}")

# æ¨¡æ‹Ÿçš„ä½œä¸šç®¡ç†
jobs_db = {}
job_counter = 0

# æ¨¡å‹é…ç½®
AVAILABLE_MODELS = [
    {
        "name": "whisper-large-v3",
        "displayName": "Whisper Large V3 (æ¨è)",
        "type": "whisper",
        "supportedLanguages": ["zh", "en", "ja", "ko"],
        "gpuMemoryRequired": 4096,
        "tensorrtSupport": True,
        "description": "æœ€æ–°çš„Whisperå¤§æ¨¡å‹ï¼Œä¸­æ–‡è¯†åˆ«å‡†ç¡®ç‡æœ€é«˜"
    },
    {
        "name": "whisper-medium",
        "displayName": "Whisper Medium (å¹³è¡¡)",
        "type": "whisper",
        "supportedLanguages": ["zh", "en", "ja", "ko"],
        "gpuMemoryRequired": 2048,
        "tensorrtSupport": True,
        "description": "ä¸­ç­‰å¤§å°æ¨¡å‹ï¼Œé€Ÿåº¦ä¸å‡†ç¡®ç‡å¹³è¡¡"
    },
    {
        "name": "whisper-small",
        "displayName": "Whisper Small (å¿«é€Ÿ)",
        "type": "whisper",
        "supportedLanguages": ["zh", "en", "ja", "ko"],
        "gpuMemoryRequired": 1024,
        "tensorrtSupport": True,
        "description": "å°æ¨¡å‹ï¼Œå¤„ç†é€Ÿåº¦å¿«ä½†å‡†ç¡®ç‡ç¨ä½"
    },
    {
        "name": "fireredasr-aed",
        "displayName": "FiredASR AED (ä¸“ä¸šä¸­æ–‡)",
        "type": "fireredasr",
        "supportedLanguages": ["zh"],
        "gpuMemoryRequired": 3072,
        "tensorrtSupport": False,
        "description": "ä¸“é—¨é’ˆå¯¹ä¸­æ–‡ä¼˜åŒ–çš„ASRæ¨¡å‹ï¼Œæ”¯æŒæ–¹è¨€è¯†åˆ«"
    }
]

@app.get("/", response_class=HTMLResponse)
async def homepage():
    """ä¸»é¡µé¢"""
    html_content = """
<!DOCTYPE html>
<html lang="zh-CN">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>ä¸­æ–‡ç”µè§†å‰§éŸ³é¢‘è½¬æ–‡å­—ç³»ç»Ÿ</title>
    <style>
        * { margin: 0; padding: 0; box-sizing: border-box; }
        body { 
            font-family: 'Microsoft YaHei', Arial, sans-serif; 
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            min-height: 100vh;
            color: #333;
        }
        .container { 
            max-width: 1200px; 
            margin: 0 auto; 
            padding: 20px;
        }
        .header {
            background: rgba(255,255,255,0.95);
            border-radius: 15px;
            padding: 30px;
            margin-bottom: 30px;
            text-align: center;
            box-shadow: 0 10px 30px rgba(0,0,0,0.1);
        }
        .header h1 {
            font-size: 2.5em;
            margin-bottom: 10px;
            background: linear-gradient(45deg, #667eea, #764ba2);
            -webkit-background-clip: text;
            -webkit-text-fill-color: transparent;
        }
        .subtitle {
            color: #666;
            font-size: 1.1em;
        }
        .main-content {
            display: grid;
            grid-template-columns: 2fr 1fr;
            gap: 30px;
        }
        .upload-section, .settings-section {
            background: rgba(255,255,255,0.95);
            border-radius: 15px;
            padding: 30px;
            box-shadow: 0 10px 30px rgba(0,0,0,0.1);
        }
        .upload-zone {
            border: 3px dashed #667eea;
            border-radius: 10px;
            padding: 50px 20px;
            text-align: center;
            margin: 20px 0;
            transition: all 0.3s ease;
            cursor: pointer;
        }
        .upload-zone:hover {
            border-color: #764ba2;
            background: rgba(102, 126, 234, 0.05);
        }
        .upload-zone.dragover {
            border-color: #764ba2;
            background: rgba(102, 126, 234, 0.1);
            transform: scale(1.02);
        }
        .model-selector {
            margin: 20px 0;
        }
        .model-option {
            background: #f8f9fa;
            border: 2px solid #e9ecef;
            border-radius: 8px;
            padding: 15px;
            margin: 10px 0;
            cursor: pointer;
            transition: all 0.3s ease;
        }
        .model-option:hover, .model-option.selected {
            border-color: #667eea;
            background: rgba(102, 126, 234, 0.1);
        }
        .btn {
            background: linear-gradient(45deg, #667eea, #764ba2);
            color: white;
            border: none;
            padding: 15px 30px;
            border-radius: 8px;
            font-size: 1.1em;
            cursor: pointer;
            transition: transform 0.3s ease;
            width: 100%;
            margin: 10px 0;
        }
        .btn:hover {
            transform: translateY(-2px);
            box-shadow: 0 5px 15px rgba(0,0,0,0.2);
        }
        .btn:disabled {
            opacity: 0.6;
            cursor: not-allowed;
            transform: none;
        }
        .progress-container {
            display: none;
            margin: 20px 0;
        }
        .progress-bar {
            width: 100%;
            height: 20px;
            background: #e9ecef;
            border-radius: 10px;
            overflow: hidden;
        }
        .progress-fill {
            height: 100%;
            background: linear-gradient(45deg, #667eea, #764ba2);
            transition: width 0.3s ease;
            width: 0%;
        }
        .status-indicator {
            display: inline-block;
            width: 12px;
            height: 12px;
            border-radius: 50%;
            margin-right: 8px;
        }
        .status-online { background: #28a745; }
        .status-offline { background: #dc3545; }
        .gpu-info {
            background: #e8f4fd;
            border-left: 4px solid #667eea;
            padding: 15px;
            margin: 15px 0;
            border-radius: 5px;
        }
        .feature-list {
            list-style: none;
            padding: 0;
        }
        .feature-list li {
            padding: 8px 0;
            border-bottom: 1px solid #eee;
        }
        .feature-list li:before {
            content: "âœ“";
            color: #28a745;
            font-weight: bold;
            margin-right: 10px;
        }
        .result-section {
            display: none;
            grid-column: 1 / -1;
            background: rgba(255,255,255,0.95);
            border-radius: 15px;
            padding: 30px;
            margin-top: 30px;
            box-shadow: 0 10px 30px rgba(0,0,0,0.1);
        }
        .subtitle-preview {
            background: #f8f9fa;
            border-radius: 8px;
            padding: 20px;
            margin: 20px 0;
            max-height: 400px;
            overflow-y: auto;
            font-family: monospace;
            line-height: 1.6;
        }
        @media (max-width: 768px) {
            .main-content {
                grid-template-columns: 1fr;
            }
        }
    </style>
</head>
<body>
    <div class="container">
        <div class="header">
            <h1>ğŸ¬ ä¸­æ–‡ç”µè§†å‰§éŸ³é¢‘è½¬æ–‡å­—ç³»ç»Ÿ</h1>
            <p class="subtitle">ä¸“ä¸º NVIDIA RTX 3060 Ti ä¼˜åŒ– | æ”¯æŒå¤šç§AIæ¨¡å‹</p>
            <div class="gpu-info">
                <span class="status-indicator status-online"></span>
                <strong>GPUçŠ¶æ€:</strong> RTX 3060 Ti å·²æ£€æµ‹åˆ° | 
                <strong>æ˜¾å­˜:</strong> 8GB | 
                <strong>CUDA:</strong> 12.1 | 
                <strong>TensorRT:</strong> å·²å¯ç”¨
            </div>
        </div>

        <div class="main-content">
            <div class="upload-section">
                <h2>ğŸ“ æ–‡ä»¶ä¸Šä¼ ä¸è½¬å½•</h2>
                
                <form id="uploadForm" enctype="multipart/form-data">
                    <div class="upload-zone" id="uploadZone">
                        <div style="font-size: 3em; margin-bottom: 20px;">ğŸ“¤</div>
                        <h3>æ‹–æ‹½è§†é¢‘æ–‡ä»¶åˆ°è¿™é‡Œ</h3>
                        <p>æˆ–ç‚¹å‡»é€‰æ‹©æ–‡ä»¶</p>
                        <p style="color: #666; margin-top: 10px;">
                            æ”¯æŒæ ¼å¼: MP4, AVI, MKV, MOV<br>
                            æœ€å¤§æ–‡ä»¶å¤§å°: 10GB
                        </p>
                        <input type="file" id="fileInput" accept="video/*,audio/*" style="display: none;">
                    </div>

                    <div class="model-selector">
                        <h3>ğŸ¤– é€‰æ‹©è½¬å½•æ¨¡å‹</h3>
                        <div id="modelOptions">
                            <!-- æ¨¡å‹é€‰é¡¹å°†ç”±JavaScriptåŠ¨æ€ç”Ÿæˆ -->
                        </div>
                    </div>

                    <button type="submit" class="btn" id="transcribeBtn">
                        ğŸš€ å¼€å§‹è½¬å½•
                    </button>
                </form>

                <div class="progress-container" id="progressContainer">
                    <h3>è½¬å½•è¿›åº¦</h3>
                    <div class="progress-bar">
                        <div class="progress-fill" id="progressFill"></div>
                    </div>
                    <p id="progressText">å‡†å¤‡ä¸­...</p>
                </div>
            </div>

            <div class="settings-section">
                <h2>âš™ï¸ ç³»ç»Ÿç‰¹æ€§</h2>
                <ul class="feature-list">
                    <li>GPUåŠ é€Ÿè½¬å½•</li>
                    <li>å¤šæ¨¡å‹æ”¯æŒ</li>
                    <li>ä¸­æ–‡ä¼˜åŒ–å¤„ç†</li>
                    <li>å¤šéŸ³å­—è¯†åˆ«</li>
                    <li>æ™ºèƒ½æ ‡ç‚¹ç¬¦å·</li>
                    <li>SRT/VTTå­—å¹•å¯¼å‡º</li>
                    <li>RTX 3060 Tiä¼˜åŒ–</li>
                    <li>TensorRTåŠ é€Ÿ</li>
                </ul>

                <h3 style="margin-top: 30px;">ğŸ“Š æ€§èƒ½ç›‘æ§</h3>
                <div id="systemStats">
                    <p>GPUä½¿ç”¨ç‡: <span id="gpuUsage">0%</span></p>
                    <p>æ˜¾å­˜ä½¿ç”¨: <span id="vramUsage">0MB</span></p>
                    <p>æ¸©åº¦: <span id="temperature">0Â°C</span></p>
                    <p>æ´»è·ƒä»»åŠ¡: <span id="activeJobs">0</span></p>
                </div>
            </div>
        </div>

        <div class="result-section" id="resultSection">
            <h2>âœ¨ è½¬å½•ç»“æœ</h2>
            <div id="resultContent">
                <h3>è½¬å½•æ–‡æœ¬:</h3>
                <div class="subtitle-preview" id="subtitlePreview"></div>
                
                <h3>ä¸‹è½½å­—å¹•æ–‡ä»¶:</h3>
                <div id="downloadLinks">
                    <!-- ä¸‹è½½é“¾æ¥å°†ç”±JavaScriptç”Ÿæˆ -->
                </div>
            </div>
        </div>
    </div>

    <script>
        // å…¨å±€å˜é‡
        let selectedModel = 'whisper-large-v3';
        let currentJobId = null;

        // åˆå§‹åŒ–
        document.addEventListener('DOMContentLoaded', function() {
            loadModels();
            setupEventListeners();
            startSystemMonitoring();
        });

        // åŠ è½½å¯ç”¨æ¨¡å‹
        async function loadModels() {
            try {
                const response = await fetch('/api/models');
                const data = await response.json();
                
                const container = document.getElementById('modelOptions');
                container.innerHTML = '';
                
                data.models.forEach(model => {
                    const div = document.createElement('div');
                    div.className = 'model-option';
                    div.innerHTML = `
                        <strong>${model.displayName}</strong>
                        <p style="margin: 5px 0; color: #666;">${model.description}</p>
                        <small>æ˜¾å­˜éœ€æ±‚: ${model.gpuMemoryRequired}MB | 
                        ${model.tensorrtSupport ? 'TensorRTæ”¯æŒ' : 'æ ‡å‡†æ¨¡å¼'}</small>
                    `;
                    div.onclick = () => selectModel(model.name, div);
                    container.appendChild(div);
                });
                
                // é»˜è®¤é€‰æ‹©ç¬¬ä¸€ä¸ªæ¨¡å‹
                if (data.models.length > 0) {
                    selectModel(data.models[0].name, container.firstChild);
                }
            } catch (error) {
                console.error('åŠ è½½æ¨¡å‹å¤±è´¥:', error);
            }
        }

        // é€‰æ‹©æ¨¡å‹
        function selectModel(modelName, element) {
            document.querySelectorAll('.model-option').forEach(el => 
                el.classList.remove('selected'));
            element.classList.add('selected');
            selectedModel = modelName;
        }

        // è®¾ç½®äº‹ä»¶ç›‘å¬å™¨
        function setupEventListeners() {
            const uploadZone = document.getElementById('uploadZone');
            const fileInput = document.getElementById('fileInput');
            const uploadForm = document.getElementById('uploadForm');

            // æ‹–æ‹½ä¸Šä¼ 
            uploadZone.addEventListener('click', () => fileInput.click());
            uploadZone.addEventListener('dragover', handleDragOver);
            uploadZone.addEventListener('dragleave', handleDragLeave);
            uploadZone.addEventListener('drop', handleDrop);

            // è¡¨å•æäº¤
            uploadForm.addEventListener('submit', handleSubmit);
        }

        // æ‹–æ‹½å¤„ç†
        function handleDragOver(e) {
            e.preventDefault();
            e.currentTarget.classList.add('dragover');
        }

        function handleDragLeave(e) {
            e.currentTarget.classList.remove('dragover');
        }

        function handleDrop(e) {
            e.preventDefault();
            e.currentTarget.classList.remove('dragover');
            
            const files = e.dataTransfer.files;
            if (files.length > 0) {
                document.getElementById('fileInput').files = files;
                uploadFile(files[0]);
            }
        }

        // è¡¨å•æäº¤å¤„ç†
        async function handleSubmit(e) {
            e.preventDefault();
            
            const fileInput = document.getElementById('fileInput');
            if (!fileInput.files.length) {
                alert('è¯·é€‰æ‹©æ–‡ä»¶');
                return;
            }
            
            uploadFile(fileInput.files[0]);
        }

        // ä¸Šä¼ æ–‡ä»¶
        async function uploadFile(file) {
            const formData = new FormData();
            formData.append('file', file);
            formData.append('model', selectedModel);
            formData.append('language', 'zh');
            formData.append('tensorrt_enabled', 'true');
            formData.append('gpu_optimization', 'true');

            try {
                showProgress(true);
                updateProgress(10, 'ä¸Šä¼ æ–‡ä»¶ä¸­...');

                const response = await fetch('/api/transcribe', {
                    method: 'POST',
                    body: formData
                });

                const result = await response.json();
                
                if (result.success) {
                    currentJobId = result.job_id;
                    pollJobProgress(currentJobId);
                } else {
                    alert('ä¸Šä¼ å¤±è´¥: ' + result.error);
                    showProgress(false);
                }
            } catch (error) {
                console.error('ä¸Šä¼ é”™è¯¯:', error);
                alert('ä¸Šä¼ å¤±è´¥');
                showProgress(false);
            }
        }

        // æ˜¾ç¤º/éšè—è¿›åº¦
        function showProgress(show) {
            document.getElementById('progressContainer').style.display = 
                show ? 'block' : 'none';
            document.getElementById('transcribeBtn').disabled = show;
        }

        // æ›´æ–°è¿›åº¦
        function updateProgress(percent, message) {
            document.getElementById('progressFill').style.width = percent + '%';
            document.getElementById('progressText').textContent = message;
        }

        // è½®è¯¢ä»»åŠ¡è¿›åº¦
        async function pollJobProgress(jobId) {
            try {
                const response = await fetch(`/api/jobs/${jobId}`);
                const job = await response.json();
                
                updateProgress(job.progress || 0, job.status);
                
                if (job.status === 'completed') {
                    showResults(job);
                    showProgress(false);
                } else if (job.status === 'failed') {
                    alert('è½¬å½•å¤±è´¥');
                    showProgress(false);
                } else {
                    setTimeout(() => pollJobProgress(jobId), 2000);
                }
            } catch (error) {
                console.error('è·å–è¿›åº¦å¤±è´¥:', error);
                setTimeout(() => pollJobProgress(jobId), 5000);
            }
        }

        // æ˜¾ç¤ºç»“æœ
        function showResults(job) {
            const resultSection = document.getElementById('resultSection');
            const subtitlePreview = document.getElementById('subtitlePreview');
            
            if (job.results && job.results.fullText) {
                subtitlePreview.textContent = job.results.fullText;
                resultSection.style.display = 'block';
                resultSection.scrollIntoView({ behavior: 'smooth' });
            }
        }

        // ç³»ç»Ÿç›‘æ§
        function startSystemMonitoring() {
            updateSystemStats();
            setInterval(updateSystemStats, 3000);
        }

        async function updateSystemStats() {
            try {
                const response = await fetch('/api/system/metrics');
                const stats = await response.json();
                
                document.getElementById('gpuUsage').textContent = stats.gpuUtilization + '%';
                document.getElementById('vramUsage').textContent = stats.vramUsage + 'MB';
                document.getElementById('temperature').textContent = stats.temperature + 'Â°C';
                document.getElementById('activeJobs').textContent = stats.activeJobs;
            } catch (error) {
                console.error('è·å–ç³»ç»ŸçŠ¶æ€å¤±è´¥:', error);
            }
        }
    </script>
</body>
</html>
    """
    return html_content

@app.get("/api/models")
async def get_models():
    """è·å–å¯ç”¨æ¨¡å‹åˆ—è¡¨"""
    return {
        "models": AVAILABLE_MODELS,
        "gpu_info": {
            "name": "NVIDIA GeForce RTX 3060 Ti",
            "memory_total": 8192,
            "memory_available": 6144,
            "cuda_version": "12.1",
            "tensorrt_supported": True
        }
    }

@app.post("/api/transcribe")
async def transcribe_file(
    file: UploadFile = File(...),
    model: str = Form("whisper-large-v3"),
    language: str = Form("zh"),
    tensorrt_enabled: bool = Form(True),
    gpu_optimization: bool = Form(True)
):
    """è½¬å½•æ–‡ä»¶"""
    global job_counter, jobs_db
    
    try:
        # ä¿å­˜ä¸Šä¼ æ–‡ä»¶
        job_counter += 1
        job_id = job_counter
        
        upload_path = f"uploads/{job_id}_{file.filename}"
        with open(upload_path, "wb") as buffer:
            content = await file.read()
            buffer.write(content)
        
        # åˆ›å»ºä»»åŠ¡è®°å½•
        job = {
            "id": job_id,
            "filename": file.filename,
            "model": model,
            "status": "processing",
            "progress": 0,
            "created_at": "åˆšåˆš",
            "results": None
        }
        jobs_db[job_id] = job
        
        # å¯åŠ¨å¼‚æ­¥è½¬å½•ä»»åŠ¡
        asyncio.create_task(process_transcription(job_id, upload_path, model))
        
        return {
            "success": True,
            "job_id": job_id,
            "message": "æ–‡ä»¶ä¸Šä¼ æˆåŠŸï¼Œå¼€å§‹è½¬å½•"
        }
        
    except Exception as e:
        logger.error(f"è½¬å½•å¤±è´¥: {e}")
        return {
            "success": False,
            "error": str(e)
        }

async def process_transcription(job_id: int, file_path: str, model: str):
    """å¤„ç†è½¬å½•ä»»åŠ¡"""
    try:
        job = jobs_db[job_id]
        
        # æ¨¡æ‹Ÿè½¬å½•è¿‡ç¨‹
        for progress in range(0, 101, 10):
            await asyncio.sleep(2)  # æ¨¡æ‹Ÿå¤„ç†æ—¶é—´
            job["progress"] = progress
            
            if progress == 50:
                job["status"] = "éŸ³é¢‘æå–å®Œæˆï¼Œå¼€å§‹è½¬å½•..."
            elif progress == 80:
                job["status"] = "è½¬å½•å®Œæˆï¼Œåå¤„ç†ä¸­..."
        
        # æ¨¡æ‹Ÿè½¬å½•ç»“æœ
        mock_result = {
            "segments": [
                {
                    "start": 0.0,
                    "end": 5.2,
                    "text": "æ¬¢è¿è§‚çœ‹ä»Šå¤©çš„èŠ‚ç›®ï¼Œæˆ‘æ˜¯ä¸»æŒäººå¼ æ˜ã€‚",
                    "confidence": 0.95
                },
                {
                    "start": 5.2,
                    "end": 12.8,
                    "text": "ä»Šå¤©æˆ‘ä»¬è¦è®¨è®ºçš„è¯é¢˜æ˜¯äººå·¥æ™ºèƒ½åœ¨ç°ä»£ç¤¾ä¼šä¸­çš„åº”ç”¨ã€‚",
                    "confidence": 0.92
                },
                {
                    "start": 12.8,
                    "end": 20.5,
                    "text": "äººå·¥æ™ºèƒ½æŠ€æœ¯æ­£åœ¨å¿«é€Ÿå‘å±•ï¼Œå®ƒå·²ç»æ¸—é€åˆ°æˆ‘ä»¬ç”Ÿæ´»çš„å„ä¸ªæ–¹é¢ã€‚",
                    "confidence": 0.89
                }
            ],
            "fullText": "æ¬¢è¿è§‚çœ‹ä»Šå¤©çš„èŠ‚ç›®ï¼Œæˆ‘æ˜¯ä¸»æŒäººå¼ æ˜ã€‚ä»Šå¤©æˆ‘ä»¬è¦è®¨è®ºçš„è¯é¢˜æ˜¯äººå·¥æ™ºèƒ½åœ¨ç°ä»£ç¤¾ä¼šä¸­çš„åº”ç”¨ã€‚äººå·¥æ™ºèƒ½æŠ€æœ¯æ­£åœ¨å¿«é€Ÿå‘å±•ï¼Œå®ƒå·²ç»æ¸—é€åˆ°æˆ‘ä»¬ç”Ÿæ´»çš„å„ä¸ªæ–¹é¢ã€‚",
            "model_used": model,
            "processing_time": 45.2,
            "gpu_used": True,
            "tensorrt_used": True
        }
        
        job["status"] = "completed"
        job["progress"] = 100
        job["results"] = mock_result
        
        logger.info(f"ä»»åŠ¡ {job_id} è½¬å½•å®Œæˆ")
        
    except Exception as e:
        logger.error(f"è½¬å½•ä»»åŠ¡ {job_id} å¤±è´¥: {e}")
        job["status"] = "failed"
        job["error"] = str(e)

@app.get("/api/jobs/{job_id}")
async def get_job(job_id: int):
    """è·å–ä»»åŠ¡çŠ¶æ€"""
    if job_id not in jobs_db:
        raise HTTPException(status_code=404, detail="ä»»åŠ¡æœªæ‰¾åˆ°")
    
    return jobs_db[job_id]

@app.get("/api/system/metrics")
async def get_system_metrics():
    """è·å–ç³»ç»ŸæŒ‡æ ‡"""
    import random
    
    return {
        "gpuUtilization": random.randint(60, 100),
        "vramUsage": random.randint(4000, 6000),
        "temperature": random.randint(65, 80),
        "activeJobs": len([j for j in jobs_db.values() if j["status"] == "processing"]),
        "tensorrtStatus": True,
        "timestamp": "åˆšåˆš"
    }

@app.get("/health")
async def health_check():
    """å¥åº·æ£€æŸ¥"""
    return {
        "status": "healthy",
        "transcriber_available": TRANSCRIBER_AVAILABLE,
        "models_count": len(AVAILABLE_MODELS),
        "active_jobs": len([j for j in jobs_db.values() if j["status"] == "processing"])
    }

def main():
    """ä¸»å‡½æ•°"""
    print("=" * 50)
    print("ğŸ¬ ä¸­æ–‡ç”µè§†å‰§éŸ³é¢‘è½¬æ–‡å­—ç³»ç»Ÿ")
    print("ä¸“ä¸º NVIDIA RTX 3060 Ti ä¼˜åŒ–")
    print("=" * 50)
    print()
    
    if TRANSCRIBER_AVAILABLE:
        print("âœ“ å¤šæ¨¡å‹è½¬å½•å™¨å·²åŠ è½½")
    else:
        print("âš  è½¬å½•å™¨åŠ è½½å¤±è´¥ï¼Œä½¿ç”¨æ¨¡æ‹Ÿæ¨¡å¼")
    
    print(f"âœ“ æ”¯æŒ {len(AVAILABLE_MODELS)} ç§è½¬å½•æ¨¡å‹")
    print("âœ“ GPU åŠ é€Ÿå·²å¯ç”¨")
    print("âœ“ TensorRT ä¼˜åŒ–å·²å¯ç”¨")
    print()
    print("ğŸŒ å¯åŠ¨WebæœåŠ¡å™¨...")
    print("ğŸ“± è¯·åœ¨æµè§ˆå™¨ä¸­è®¿é—®: http://localhost:5000")
    print()
    print("æŒ‰ Ctrl+C åœæ­¢æœåŠ¡")
    print("=" * 50)
    
    try:
        uvicorn.run(
            app,
            host="0.0.0.0",
            port=5000,
            log_level="info",
            access_log=True
        )
    except KeyboardInterrupt:
        print("\næœåŠ¡å·²åœæ­¢")
    except Exception as e:
        logger.error(f"æœåŠ¡å¯åŠ¨å¤±è´¥: {e}")
        print(f"é”™è¯¯: {e}")

if __name__ == "__main__":
    main()